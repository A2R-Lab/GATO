In this section, we describe the design of GATO as visualized in Figure~\ref{fig:design}. Our solver architecture is optimized for GPU-parallel computations across tens to low-hundreds of trajectory optimization solves, each with tens to low-hundreds of timesteps. This paradigm, as noted in the introduction, is commonly found across robotics applications and is underserved by current solvers. Our overall design is inspired by MPCGPU~\cite{adabag2024mpcgpu} and leverages a similar GPU-first architecture and overall 3 step design flow. However, while MPCGPU is customized for single-solve performance, we designed a new underlying solver to enable high-performance parallelism across multiple solves without losing solver accuracy. We also implemented a number of additional fine-grained parallelism optimizations both across and within solves. As shown in Section~\ref{sec:results} this results in a more performant solver across all batch-sizes. In the remainder of this section we detail our design.

\subsection{Batched Problem Setup and Line Search}
GATO is designed to maximize all possible parallelism arising from the computational structure of the underlying (batched) optimal control problems. This is most apparent in the problem setup and line search steps (shown as steps a and c in Figure~\ref{fig:design}). Here we need to form $S$, $\gamma$, and $\Phi^{-1}$ leveraging gradients and hessians of the costs and dynamics functions across all problems and timesteps ($N*M$ total timesteps), as well as compute the merit function values, again leveraging underlying cost and dynamics calculations, across all problems, timesteps, and line search iterates ($N*M*\mathcal{A}$ total timesteps). As such, we leverage block-based parallelism for each timestep to maximize both the independent nature of these computations, as well as opportunities for within computation thread-based parallelism. We use the GRiD~\cite{plancher2022grid} library to ensure efficient dynamics (gradient) computations, which follows a similar computational model. The merit function proceeds similarly, leveraging block-level parallelism for the cost and dynamics function calls per timestep, with thread-level parallelism for the underlying small-scale linear algebra.

Importantly, because all computations to form $S$, $\gamma$, and each timestep's merit function are block-local, only cheap \emph{intra}-block synchronizations are required. Only a single \emph{grid-wide} synchronization is required to finalize $\Phi^{-1}$, and block-level parallelism can be used to reduce each merit function for each line search iterate across all batches of solves.

Throughout these computations, all temporary variables are computed in fast shared memory and all final matrices and vectors are laid out densely and contiguously in global memory to maximize naturally coalesced loads and stores by the downstream PCG solver. Most importantly, only the current system state(s) and goal(s) are provided from the CPU host and only the final resulting state and control trajectories are sent back to the host. As such, round-trip CPU-GPU data transfers are minimized, ensuring that per-iteration latency is dominated by GPU compute rather than transfer overhead. \todo{@Alex is this true?}

% \todo{Details about the problem setup and how we parallelize by block across all things to form S,gamma,phi\_inv - mention Contiguous memory allocation and multi-dimensional threading - talk about reduced syncs because all block-wise so only at end - one mega-sync for the final phi\_inv but that's it rest is in blocks - and level warp level constructs and GRiD to minimize those.}

% \todo{from parallel problem formation, leveraging GRiD~\cite{plancher2022grid} for fast parallel physics; }

% \todo{This one will focus on the large-scale parallelism to compute all of the merit function values etc. and then the one sync and then block level-reducitons per problem/alpha to get to the final values to spit out the best steps per solve}

% \todo{ to large-scale parallelism across all line search iterates and merit-function computations.}

% - Line search now handled in parallel on device \todo{was it not this way in MPCGPU?!?}
% - All matrices/vectors packed densely across knots, block rows, and batches
% - Everything kept on device except for XU and goal traj
% - Only CPU-GPU sync at the end of entire sqp solve

\subsection{Batched PCG}
A key factor of our overall performance is our new batched PCG solver which is built around per-block PCG solves with underlying  finer-grained warp-level parallel linear algebra.\footnote{A ``warp'' represents 32 contiguous threads on the same GPU-core. These threads work in lock-step due to the design of NVIDIA GPU hardware. By exploiting their native forced synchronization at the hardware level, further acceleration of software can be achieved.} This design not only improves computational throughput but also leverages better memory access patterns, reduces synchronizations, and improves overall hardware resource utilization both for a single solve and most importantly for batches of solves. %As demonstrated in our preliminary results (Section~\ref{sec:results}), these design decisions enable much better scalability of our approach for our target problem sizes and domains.

Each CUDA thread block is assigned one KKT (or reduced) linear system; within that block, warps distribute work over knot points, and individual threads within a warp operate on rows/columns of the per-knot state/control blocks. This mapping eliminates inter-block coordination entirely: all PCG iterations, vector updates, and local reductions are resolved inside the block, avoiding cooperative groups and enabling portability across devices and launch contexts.

All matrices/vectors are packed contiguously in row-major order by batch and knot points, exploiting the block tridiagonal structure of the $S$ and $\Phi^{-1}$ matrices. This yields coalesced loads/stores for warp-strided accesses and makes warp shuffle intrinsics efficient for reductions. We also pad leading dimensions to multiples of the warp size to remove bounds checks and branch divergence. This enables us to implement a \emph{warp-optimized} block tridiagonal matrix-vector multiplication routine that (i) uses shared memory tiles to stage the current and neighboring blocks, (ii) performs thread-parallel fused multiply–adds for the block-dense operations, (iii) pipelines loads to hide any memory latency (through the use of \texttt{cudaMemcpyAsync}), and (iv) avoids atomics or grid-wide barriers. As a result, each PCG solve proceeds efficiently and fully independently. \todo{@Alex is this all true}

We note that unlike with MPCGPU~\cite{adabag2024mpcgpu} we avoid this use of NVIDIA's \texttt{cooperative groups} API which makes the solver usable in more launch scenarios and across a wider range of devices as not all blocks need to be co-resident during solves. The kernel’s shared-memory footprint and register usage are a;sp tuned to maintain high occupancy while preventing register spilling for typical state/control sizes seen in MPC applications. \todo{@Alex is this all true}

Finally, we partially unroll all inner loops over small, compile-time dimensions to reduce loop overhead, and compile with aggressive optimization flags (e.g., \texttt{-O3}) and enable fast math only where it preserves solver accuracy.  \todo{@Alex is this all true} As shown in Section~\ref{sec:results}, these choices translate to superior performance across all batch sizes in our target domain.

\todo{@alex anything I skipped that you think would be important to note in this section?}

\todo{TBD if we add a breakdown of timing figure and talk about it -- we may be able to skip that as it may be more confusing than helpful for readers.}
