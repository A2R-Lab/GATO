{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched SQP: Hyperparameter Sweep and Convergence\n",
    "\n",
    "This notebook evaluates batched SQP convergence by sweeping per-batch `rho` and global cost weights (`q_cost`, `qd_cost`, `u_cost`).\n",
    "It plots the average, normalized best-merit per iteration across 100 random targets for multiple batch sizes and a single-solve adaptive-ρ baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, numpy as np, matplotlib.pyplot as plt\n",
    "import pickle\n",
    "sys.path.append('python')\n",
    "from bsqp.interface import BSQP\n",
    "np.set_printoptions(precision=3, linewidth=160)\n",
    "\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "\n",
    "# Color palette\n",
    "color_palette = {\n",
    "    '1 (ρ=1e-1)': '#003192',  # rho=1e-1\n",
    "    '1 (ρ=1e-3)': '#56B4E9',  # rho=1e-3\n",
    "    '2': '#8B4513',         # brown\n",
    "    '4': '#747474',\n",
    "    '8': '#7030A0',\n",
    "    '16': '#F19759',\n",
    "    '32': '#00693E',\n",
    "    '64': '#00693E',\n",
    "    '128': '#FF6600'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea886c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_solver(batch_size, q_cost, qd_cost, u_cost, N_cost, *, adapt_rho, rho_batch=None, rho=1e-3):\n",
    "    return BSQP(\n",
    "        model_path=urdf_path, batch_size=batch_size, N=N, dt=dt,\n",
    "        max_sqp_iters=MAX_ITERS, kkt_tol=0.0, max_pcg_iters=MAX_PCG_ITERS, pcg_tol=PCG_TOL, solve_ratio=1.0,\n",
    "        mu=MU, q_cost=q_cost, qd_cost=qd_cost, u_cost=u_cost, N_cost=N_cost,\n",
    "        q_lim_cost=Q_LIM_COST, vel_lim_cost=VEL_LIM_COST, ctrl_lim_cost=CTRL_LIM_COST,\n",
    "        rho=rho, rho_batch=rho_batch, adapt_rho=adapt_rho, robot_type='iiwa14'\n",
    "    )\n",
    "\n",
    "def sample_goal():\n",
    "    x = np.random.uniform(-0.8, 0.8)\n",
    "    y = np.random.uniform(-0.8, 0.8)\n",
    "    z = np.random.uniform(0.2, 0.8)\n",
    "    return np.array([x, y, z, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "def _best_curve_from_stats(stats):\n",
    "    best = stats.get('best_merit_per_iter', None)\n",
    "    if best is None:\n",
    "        ls = np.asarray(stats.get('min_merit', None))\n",
    "        if ls is None:\n",
    "            raise RuntimeError('min_merit not found in stats')\n",
    "        if ls.ndim == 2:\n",
    "            best = np.min(ls, axis=1)\n",
    "        elif ls.ndim == 1:\n",
    "            best = ls\n",
    "        else:\n",
    "            raise RuntimeError(f'Unexpected min_merit ndim={ls.ndim}, shape={ls.shape}')\n",
    "    return np.asarray(best, dtype=np.float32).reshape(-1)\n",
    "\n",
    "def get_best_curve_for_B(B, q_cost, qd_cost, u_cost, N_cost, ee_goal6):\n",
    "    fractions = np.arange(1, B+1) / (B + 1)  # [1/(B+1), 2/(B+1), ..., B/(B+1)]\n",
    "    rho_vals = [RHO_MIN_EXP + f * (RHO_MAX_EXP - RHO_MIN_EXP) for f in fractions]\n",
    "    rho_vals = np.power(10, rho_vals).astype(np.float32)\n",
    "    solver = build_solver(B, q_cost, qd_cost, u_cost, N_cost, adapt_rho=True, rho_batch=rho_vals)\n",
    "    nx = solver.nx; nu = solver.nu\n",
    "    x0 = np.zeros(nx, dtype=np.float32)\n",
    "    x0_B = np.tile(x0, (B, 1))\n",
    "    ref_traj_one = np.tile(ee_goal6, N).astype(np.float32)\n",
    "    ref_B = np.tile(ref_traj_one, (B, 1))\n",
    "    XU_B = np.zeros((B, solver.N * (nx + nu) - nu), dtype=np.float32)\n",
    "    XU_B[:, :nx] = x0_B\n",
    "    solver.solve(x0_B, ref_B, XU_B)\n",
    "    stats = solver.get_stats()\n",
    "    denom = float(stats.get('best_initial_merit', np.nan))\n",
    "    curve = _best_curve_from_stats(stats)\n",
    "    curve = curve / denom if (denom and denom==denom and denom!=0) else curve\n",
    "    return np.r_[1.0, curve]\n",
    "\n",
    "def get_best_curve_adaptive(q_cost, qd_cost, u_cost, N_cost, ee_goal6, rho):\n",
    "    solver = build_solver(1, q_cost, qd_cost, u_cost, N_cost, adapt_rho=True, rho_batch=None, rho=rho)\n",
    "    nx = solver.nx; nu = solver.nu\n",
    "    x0 = np.zeros(nx, dtype=np.float32)\n",
    "    x1 = x0.reshape(1,-1)\n",
    "    ref_traj_one = np.tile(ee_goal6, N).astype(np.float32)\n",
    "    ee1 = ref_traj_one.reshape(1,-1)\n",
    "    XU_B = np.zeros((1, solver.N * (nx + nu) - nu), dtype=np.float32)\n",
    "    XU_B[:, :nx] = x1\n",
    "    solver.solve(x1, ee1, XU_B)\n",
    "    stats = solver.get_stats()\n",
    "    denom = float(stats.get('best_initial_merit', np.nan))\n",
    "    curve = _best_curve_from_stats(stats)\n",
    "    curve = curve / denom if (denom and denom==denom and denom!=0) else curve\n",
    "    return np.r_[1.0, curve]\n",
    "\n",
    "def run_config(q_cost, qd_cost, u_cost, N_cost):\n",
    "    # Collect normalized curves per label across NUM_TARGETS\n",
    "    per_label_curves = {'1 (ρ=1e-1)': [], '1 (ρ=1e-3)': [], **{f'{B}': [] for B in B_list}}\n",
    "    for _ in range(NUM_TARGETS):\n",
    "        goal = sample_goal()\n",
    "        raw = {}  # label -> raw best curve (no normalization yet)\n",
    "        for B in B_list:\n",
    "            try:\n",
    "                raw[f'{B}'] = get_best_curve_for_B(B, q_cost, qd_cost, u_cost, N_cost, goal)\n",
    "            except Exception as e:\n",
    "                print(f'Skipping B={B}: {e}')\n",
    "        try:\n",
    "            raw['1 (ρ=1e-1)'] = get_best_curve_adaptive(q_cost, qd_cost, u_cost, N_cost, goal, rho=1e-1)\n",
    "        #     raw['1 (ρ=1e-3)'] = get_best_curve_adaptive(q_cost, qd_cost, u_cost, N_cost, goal, rho=1e-3)\n",
    "        except Exception as e:\n",
    "            print(f'Skipping adaptive baseline: {e}')\n",
    "        # Normalize all iterations by the WORST 'best-merit' at iter 1 across labels (scalar)\n",
    "        valid_curves = [v for v in raw.values() if v is not None and len(v) > 0]\n",
    "        if not valid_curves:\n",
    "            continue\n",
    "        Kmin = min(len(v) for v in valid_curves)\n",
    "        stack = np.vstack([v[:Kmin] for v in valid_curves])\n",
    "        first_iter_vals = stack[:, 0]\n",
    "        denom = float(np.max(first_iter_vals))\n",
    "        if denom == 0.0: denom = 1.0\n",
    "        for label, curve in raw.items():\n",
    "            if curve is None or len(curve) == 0:\n",
    "                continue\n",
    "            per_label_curves[label].append((curve[:Kmin] / denom).astype(np.float32))\n",
    "    # Average normalized curves per label\n",
    "    results = {}\n",
    "    for label, curves in per_label_curves.items():\n",
    "        if not curves:\n",
    "            continue\n",
    "        Kmin = min(len(c) for c in curves)\n",
    "        M = np.vstack([c[:Kmin] for c in curves])\n",
    "        results[label] = np.mean(M, axis=0)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters (edit here)\n",
    "urdf_path = 'iiwa_description/iiwa14.urdf'\n",
    "N = 64                     # knots\n",
    "dt = 0.05                  # time step [s]\n",
    "B_list = [2, 4, 8, 16, 32, 64, 128]       # batch sizes to compare\n",
    "NUM_TARGETS = 50          # number of random target points\n",
    "MAX_ITERS = 100            # SQP iterations\n",
    "MAX_PCG_ITERS = 200\n",
    "PCG_TOL = 1e-3\n",
    "MU = 1.0\n",
    "Q_LIM_COST = 0.0\n",
    "VEL_LIM_COST = 0.0\n",
    "CTRL_LIM_COST = 0.0\n",
    "# Rho sweep (batched per iteration)\n",
    "RHO_MIN_EXP = -8\n",
    "RHO_MAX_EXP = 1\n",
    "# Global cost sweep (each combo is a separate experiment)\n",
    "Q_LIST = [10.0, 1.0]            # state cost\n",
    "QD_LIST = [1e-1, 1e-3, 1e-5]         # velocity cost\n",
    "U_LIST = [1e-6, 1e-7]          # control cost\n",
    "N_LIST = [100.0, 10.0]\n",
    "# Reproducibility\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5744fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across all runs and also plot per-cost figures\n",
    "# Check if we have saved results\n",
    "RESULTS_FILE = 'gato_hparam_batch_results.pkl'\n",
    "LOAD_FROM_FILE = False  # Set to True to skip experiments and load from file\n",
    "\n",
    "if LOAD_FROM_FILE and os.path.exists(RESULTS_FILE):\n",
    "    print(f\"Loading results from {RESULTS_FILE}\")\n",
    "    with open(RESULTS_FILE, 'rb') as f:\n",
    "        agg = pickle.load(f)\n",
    "else:\n",
    "    agg = {}  # label -> list of avg normalized curves per cost-config\n",
    "    for q_cost in Q_LIST:\n",
    "        for qd_cost in QD_LIST:\n",
    "            for u_cost in U_LIST:\n",
    "                for N_cost in N_LIST:\n",
    "                    results = run_config(q_cost, qd_cost, u_cost, N_cost)\n",
    "                    # Accumulate for final aggregation\n",
    "                    for label, avg_curve in results.items():\n",
    "                        agg.setdefault(label, []).append(avg_curve)\n",
    "                        \n",
    "                    print(f'q={q_cost}, qd={qd_cost}, u={u_cost}, N={N_cost}')\n",
    "                    # Per-cost plot\n",
    "                #     plt.figure(figsize=(7,5))\n",
    "                #     for label, avg_curve in results.items():\n",
    "                #         color = color_palette.get(label, None)\n",
    "                #         plt.plot(np.arange(len(avg_curve)), avg_curve, label=label, color=color)\n",
    "                #     plt.xlabel('SQP iterations')\n",
    "                #     plt.ylabel('Relative merit')\n",
    "                #     plt.title(f'Avg normalized merit (q={q_cost}, qd={qd_cost}, u={u_cost}, N={N_cost})')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "    \n",
    "    # Save results to pickle file\n",
    "    print(f\"Saving results to {RESULTS_FILE}\")\n",
    "    with open(RESULTS_FILE, 'wb') as f:\n",
    "        pickle.dump(agg, f)\n",
    "\n",
    "# Final aggregated plot across all runs\n",
    "final_avg = {}\n",
    "for label, curves in agg.items():\n",
    "    print(label)\n",
    "    if not curves:\n",
    "        continue\n",
    "    Kmin = min(len(c) for c in curves)\n",
    "    M = np.vstack([c[:Kmin] for c in curves])\n",
    "    final_avg[label] = np.mean(M, axis=0)\n",
    "# Use common length across labels for plotting\n",
    "if final_avg:\n",
    "    Kcommon = min(len(v) for v in final_avg.values())\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for label, curve in final_avg.items():\n",
    "        color = color_palette.get(label, None)\n",
    "        plt.plot(np.arange(0, Kcommon), curve[:Kcommon], label=label, color=color)\n",
    "    plt.xlabel('SQP iterations')\n",
    "    plt.ylabel('Relative merit')\n",
    "    plt.title('')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and plot from saved results (without rerunning experiments)\n",
    "RESULTS_FILE = 'gato_hparam_batch_results.pkl'\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "\n",
    "# Color palette\n",
    "color_palette = {\n",
    "    '1 (ρ=1e-1)': '#003192',  # rho=1e-1\n",
    "    '1 (ρ=1e-3)': '#56B4E9',  # rho=1e-3\n",
    "    '1':   '#003192',  # dark blue (matches previous figure)\n",
    "    '4':   '#F19759',  # orange (matches previous figure)\n",
    "    '8':   '#747474',  # gray (matches previous figure)\n",
    "    '16':  '#7030A0',  # purple (matches previous figure)\n",
    "    '32':  '#00693E',  # green (matches previous figure)\n",
    "    '64':  '#56B4E9',  # sky blue (distinct from dark blue)\n",
    "    '128': '#9A2132',  # dark red (new color)\n",
    "}\n",
    "\n",
    "\n",
    "if os.path.exists(RESULTS_FILE):\n",
    "    print(f\"Loading results from {RESULTS_FILE}\")\n",
    "    with open(RESULTS_FILE, 'rb') as f:\n",
    "        agg = pickle.load(f)\n",
    "    \n",
    "    # Create final aggregated plot\n",
    "    final_avg = {}\n",
    "    for label, curves in agg.items():\n",
    "        print(label)\n",
    "        if not curves:\n",
    "            continue\n",
    "        Kmin = min(len(c) for c in curves)\n",
    "        M = np.vstack([c[:Kmin] for c in curves])\n",
    "        final_avg[label] = np.mean(M, axis=0)\n",
    "    \n",
    "    # Plot\n",
    "    if final_avg:\n",
    "        Kcommon = min(len(v) for v in final_avg.values())\n",
    "        plt.figure(figsize=(8,6))\n",
    "        for label, curve in final_avg.items():\n",
    "            if label == '1 (ρ=1e-1)':\n",
    "                label = '1'\n",
    "            color = color_palette.get(str(label), 'red')\n",
    "            plt.plot(np.arange(0, Kcommon), curve[:Kcommon], label=label, color=color)\n",
    "        plt.xlabel('SQP iterations')\n",
    "        plt.ylabel('Relative merit')\n",
    "        plt.title('')\n",
    "        plt.grid(True)\n",
    "        plt.legend(title='Batch Size')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\"No saved results found at {RESULTS_FILE}. Run the experiments first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98591de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
